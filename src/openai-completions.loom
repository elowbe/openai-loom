raw,,(-1270.0,-270.0),,[67, 111, 110, 116, 101, 110, 116, 45, 84, 121, 112, 101, 58, 32, 97, 112, 112, 108, 105, 99, 97, 116, 105, 111, 110, 47, 106, 115, 111, 110, 10, 65, 117, 116, 104, 111, 114, 105, 122, 97, 116, 105, 111, 110, 58, 32, 66, 101, 97, 114, 101, 114, 32, 123, 97, 112, 105, 107, 101, 121, 125],,plain text,,false
replace,,(-46.0,82.0),,[123, 97, 112, 105, 107, 101, 121, 125],,[]
env,,(-625.0,229.0),,OPENAI_API_KEY
curl,,(875.0,312.0),,false,,[104, 116, 116, 112, 115, 58, 47, 47, 97, 112, 105, 46, 111, 112, 101, 110, 97, 105, 46, 99, 111, 109, 47, 118, 49, 47, 99, 111, 109, 112, 108, 101, 116, 105, 111, 110, 115],,[],,[],,false
expose_input,,(-625.0,458.0),,prompt,,[119, 104, 101, 110, 32, 104, 101],,Text,,0,,0,,[]
json_create,,(120.0,475.0),,[112, 108, 97, 99, 101, 104, 111, 108, 100, 101, 114],,false,,prompt,model,max_tokens,temperature,top_p,frequency_penalty,presence_penalty,user,
expose_input,,(-625.0,854.0),,model,,[100, 97, 118, 105, 110, 99, 105, 45, 48, 48, 50],,Text,,0,,0,,[]
expose_input,,(-270.0,854.0),,max_tokens,,[53, 48, 46, 48],,Number,,0,,0,,[]
expose_input,,(-604.0,1250.0),,temperature,,[48, 46, 55, 48, 50, 50, 49, 50, 50, 49, 52, 52, 54, 57, 57, 48, 57, 55],,Number,,0,,1,,[]
expose_input,,(-270.0,1333.0),,top_p,,[49, 46, 48],,Number,,0,,1,,[]
expose_input,,(-604.0,1750.0),,freq_penalty,,[48, 46, 48],,Number,,0,,1,,[]
expose_input,,(-270.0,1833.0),,pres_penalty,,[48, 46, 48],,Number,,0,,1,,[]
expose_input,,(-625.0,2250.0),,user,,[],,Text,,0,,0,,[]
probe,,(2020.0,0.0),,false
json_extract,,(1729.0,833.0),,[112, 108, 97, 99, 101, 104, 111, 108, 100, 101, 114],,false,,usage,choices,
json_extract,,(2062.0,854.0),,[112, 108, 97, 99, 101, 104, 111, 108, 100, 101, 114],,false,,total_tokens,
expose_output,,(2645.0,1375.0),,output,,false,,Text
json_extract,,(2062.0,1145.0),,[112, 108, 97, 99, 101, 104, 111, 108, 100, 101, 114],,false,,0,
json_extract,,(2333.0,1362.0),,[112, 108, 97, 99, 101, 104, 111, 108, 100, 101, 114],,false,,text,
expose_output,,(2500.0,979.0),,total_tokens,,false,,Number
probe,,(2980.0,983.0),,false
probe,,(3024.0,1479.0),,true
connections:1:text>0:out,1:replacement>2:get,3:header>1:output,3:data>5:json,5:prompt>4:terminal0,5:model>6:terminal0,5:max_tokens>7:terminal0,5:temperature>8:terminal0,5:top_p>9:terminal0,5:frequency_penalty>10:terminal0,5:presence_penalty>11:terminal0,5:user>12:terminal0,13:probe>3:response,14:json>3:response,15:json>14:usage,16:terminal0>18:text,17:json>14:choices,18:json>17:0,19:terminal0>15:total_tokens,20:probe>15:total_tokens,21:probe>18:text,
.port=80